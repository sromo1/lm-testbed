{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe2c45eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set project_root: /home/sromo/Repos/lm-testbed\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parents[0]\n",
    "os.chdir(project_root)\n",
    "print(\"Set project_root:\", project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edcbcd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from src.models.GPT2 import GPTModel\n",
    "from src.configs.GPT2 import GPT_CONFIG_124M\n",
    "\n",
    "GPT_CONFIG_124M = GPT_CONFIG_124M.copy()\n",
    "GPT_CONFIG_124M[\"context_length\"] = 256 # Reduce context length to reduce computational demands\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96a81c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model input:\n",
      " tensor([[6109, 3626, 6100,  345]])\n",
      "\n",
      "Model output:\n",
      " tensor([[ 6109,  3626,  6100,   345, 34245,  5139,  2492, 25405, 17434, 17853,\n",
      "          5308,  3398, 13174, 43071]])\n",
      "\n",
      "Output text:\n",
      " Every effort moves you rentingetic wasnÙ… refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from src.utils.generate import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text:str, tokenizer:tiktoken.core.Encoding):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)         # Adds the batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids:torch.Tensor, tokenizer:tiktoken.core.Encoding):\n",
    "    flat = token_ids.squeeze(0)     # Removes the batch dimension\n",
    "    decoded = tokenizer.decode(flat.tolist())\n",
    "    return decoded\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "print(\"Model input:\\n\", text_to_token_ids(start_context, tokenizer))\n",
    "print(\"\\nModel output:\\n\", token_ids)\n",
    "print(\"\\nOutput text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74dbbfb",
   "metadata": {},
   "source": [
    "**Calculating the text generation loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90b7b4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n",
      "\n",
      "Output token IDs:\n",
      " tensor([[[16657],\n",
      "         [  339],\n",
      "         [42826]],\n",
      "\n",
      "        [[49906],\n",
      "         [29669],\n",
      "         [41751]]])\n",
      "\n",
      "Targets batch 1:  effort moves you\n",
      "            tensor([3626, 6100,  345])\n",
      "\n",
      "Outputs batch 1:  Armed heNetflix\n",
      "         tensor([16657,   339, 42826])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.tensor([[16833,  3626,  6100],     # [\"every effort moves\",\n",
    "                       [40,     1107,   588]])    # \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345],        # [\" effort moves you\",\n",
    "                        [  40, 1107, 588]])       #  \" really like chocolate\"]\n",
    "\n",
    "with torch.no_grad():    # Disable gradient tracking since we are not training yet\n",
    "    logits = model(inputs)\n",
    "probas = torch.softmax(logits, dim=-1)  # (batch_size, n_tokens, emb_dim)\n",
    "print(probas.shape)\n",
    "\n",
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "print(\"\\nOutput token IDs:\\n\", token_ids)\n",
    "\n",
    "print(f\"\\nTargets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(\"           \",targets[0])\n",
    "print(f\"\\nOutputs batch 1:\"\n",
    "      f\" {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")\n",
    "print(f\"        \",token_ids[0].squeeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "466aa64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1:\n",
      " tensor([7.4540e-05, 3.1061e-05, 1.1563e-05])\n",
      "\n",
      "Text 2:\n",
      " tensor([4.2743e-05, 2.5524e-05, 2.1971e-05])\n"
     ]
    }
   ],
   "source": [
    "# Probability scores for each target\n",
    "text_idx = 0\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]   # (batch, n_tokens, emb_dim) - Probability for the CORRECT next tokens\n",
    "print(\"Text 1:\\n\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"\\nText 2:\\n\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191ebd39",
   "metadata": {},
   "source": [
    "**Calculating the loss of for the probability scores**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f89bd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_probas:\n",
      " tensor([ -9.5042, -10.3796, -11.3677, -10.0603, -10.5759, -10.7258])\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2))) # Concatenate to allow torch.log and torch.mean operate on the entire predictions simultaneously\n",
    "print(\"log_probas:\\n\", log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a8dda58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg_log_probas:\n",
      " tensor(-10.4356)\n"
     ]
    }
   ],
   "source": [
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(\"avg_log_probas:\\n\", avg_log_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bda7282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.4356)\n"
     ]
    }
   ],
   "source": [
    "neg_avg_log_probas = avg_log_probas * -1\n",
    "print(neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbb0f51",
   "metadata": {},
   "source": [
    "**Pytorch's cross entropy function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f57a2b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([2, 3, 50257])\n",
      "Targets shape: torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Recall\n",
    "print(\"Logits shape:\", logits.shape)\n",
    "print(\"Targets shape:\", targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75df6861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits:\n",
      " torch.Size([6, 50257])\n",
      "\n",
      "Flattened targets:\n",
      " torch.Size([6])\n"
     ]
    }
   ],
   "source": [
    "# For the cross_entropy loss function in PyTorch we need to flatten these tensors by combining them over the batch dimension\n",
    "logits_flat = logits.flatten(0,1)\n",
    "targets_flat = targets.flatten()\n",
    "\n",
    "print(\"Flattened logits:\\n\", logits_flat.shape)\n",
    "print(\"\\nFlattened targets:\\n\", targets_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f834cecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.4356)\n"
     ]
    }
   ],
   "source": [
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7e73c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: tensor(34049.6641)\n"
     ]
    }
   ],
   "source": [
    "# Perplexity measures how well the model matches the distribution of words in the dataset. Analogous to the vocabulary size the model is uncertain at each step\n",
    "\n",
    "perplexity = torch.exp(loss)\n",
    "print(\"Perplexity:\", perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d38538",
   "metadata": {},
   "source": [
    "**Calculating the training and validation set losses**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6db123a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters:  20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "file_path = project_root / \"data\" / \"raw\" / \"the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    text_data = f.read()\n",
    "\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters: \", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "205d0bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4948d7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader (x-input data, y-target data):\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader: (x-input data, y-target data)\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "from src.dataloaders.GPT import create_dataloader_v1\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size = 2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size = 2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "print(\"Train loader (x-input data, y-target data):\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader: (x-input data, y-target data)\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3eb8ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch:torch.Tensor, target_batch:torch.Tensor, model:torch.nn.Module, device:torch.device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0,1), target_batch.flatten()\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches:int = None):\n",
    "    \"\"\" Returns the average loss across all batches in a data loader\"\"\"\n",
    "    total_loss = 0\n",
    "    if len(data_loader) == 0:\n",
    "        return float (\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)      # Itereatives over all batches if no fixed num_batches specified\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader)) # Reduces num_batches to match the total number of batches in the data loader if num_batches exceeds ir\n",
    "\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85051b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss:\n",
      " 10.987583372328016\n",
      "\n",
      "Validation loss:\n",
      " 10.981104850769043\n"
     ]
    }
   ],
   "source": [
    " # USAGE\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "with torch.no_grad():       # Disable gradient tracking for efficiency because we are not training yet\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "print(\"Training loss:\\n\", train_loss)\n",
    "print(\"\\nValidation loss:\\n\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af127b3f",
   "metadata": {},
   "source": [
    "**Training an LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a82c700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import tiktoken\n",
    "\n",
    "from src.loss.cross_entropy import calc_loss_batch, calc_loss_loader\n",
    "from src.utils.token_converter import text_to_token_ids, token_ids_to_text\n",
    "from src.utils.generate import generate_text_simple\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model:nn.Module, tokenizer:tiktoken.core.Encoding, device:torch.device, start_context:str):\n",
    "    \"\"\"\n",
    "    Given a start context, generate text using a language model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model (nn.Module):\n",
    "        Language model.\n",
    "    tokenizer (tiktoken.core.Encoding):\n",
    "        Model tokenizer.\n",
    "    device (troch.device):\n",
    "        Device to generate in.\n",
    "    start_context (str)\n",
    "        Text to serve as start context for the model.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded, \n",
    "            max_new_tokens=50, context_size=context_size\n",
    "            )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()\n",
    "\n",
    "\n",
    "def evaluate_model(model:nn.Module, train_loader:DataLoader, val_loader:DataLoader, device:torch.device, eval_iter:int):\n",
    "    \"\"\"\n",
    "    Calculate model training and validation losses.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model (nn.Module):\n",
    "        Language model.\n",
    "    train_loader (DataLoader):\n",
    "        DataLoader with training data.\n",
    "    val_loader (DataLoader):\n",
    "        Dataloader with validation data.\n",
    "    device (torch.device):\n",
    "        Device to procees training and validation data.\n",
    "    eval_iter (int):\n",
    "        Number of batches to calculate the loss on.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    train_loss (float):\n",
    "        Average training loss across batches.\n",
    "    val_loss (float):\n",
    "        Average validation loss across batches.\n",
    "    \"\"\"\n",
    "    model.eval()    # Disable dropout during evaluation for stable, reproducible results\n",
    "    with torch.no_grad():   # Disable gradient tracking to reduce computational overhead\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def train_model_simple(model:nn.Module, train_loader:DataLoader, val_loader:DataLoader, \n",
    "                       optimizer, device:torch.device, num_epochs:int, \n",
    "                       eval_freq:int, eval_iter:int, start_context:str, tokenizer:tiktoken.core.Encoding):\n",
    "    \"\"\"\n",
    "    Simple model training function for a language model. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model (nn.Module):\n",
    "        Language model.\n",
    "    train_loader (DataLoader):\n",
    "        DataLoader with training data.\n",
    "    val_loader (DataLoader):\n",
    "        Dataloader with validation data.\n",
    "    optimizer (torch.optim):\n",
    "        Optimizer used for training.\n",
    "    device (torch.device):\n",
    "        Device to procees training and validation data.\n",
    "    num_epochs (int):\n",
    "        Number of epochs to train the model for.\n",
    "    eval_freq (int):\n",
    "        Epoch frequency in which to evaluate the model.\n",
    "    eval_iter (int):\n",
    "        Number of batches to calculate the loss on.\n",
    "    start_context (str)\n",
    "        Text to serve as start context for the model.\n",
    "    tokenizer (tiktoken.core.Encoding):\n",
    "        Model tokenizer.    \n",
    "    \"\"\"\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []        # Initialize lists to track losses and tokens seen\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()       # Resets loss gradients from the previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()             # Calculates loss gradients\n",
    "            optimizer.step()            # Updates model weights using loss gradients\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter\n",
    "                )\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss: {train_loss:.3f}, \"\n",
    "                      f\"Val loss: {val_loss:.3f}\"\n",
    "                )\n",
    "        \n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dec852bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss: 9.825, Val loss: 9.931\n",
      "Ep 1 (Step 000005): Train loss: 8.069, Val loss: 8.341\n",
      "Every effort moves you,,,,,,,,,,,,,,.                                   \n",
      "Ep 2 (Step 000010): Train loss: 6.625, Val loss: 7.051\n",
      "Ep 2 (Step 000015): Train loss: 6.048, Val loss: 6.599\n",
      "Every effort moves you, and,, and,,,,,,,,,.                                   \n",
      "Ep 3 (Step 000020): Train loss: 5.574, Val loss: 6.494\n",
      "Ep 3 (Step 000025): Train loss: 5.504, Val loss: 6.413\n",
      "Every effort moves you, and, and, and, and, and, and, and of the of the of the of the to to to the to to the of the of the of the of the of the's, and, and, and, and, and\n",
      "Ep 4 (Step 000030): Train loss: 5.078, Val loss: 6.322\n",
      "Ep 4 (Step 000035): Train loss: 4.836, Val loss: 6.315\n",
      "Every effort moves you a the picture. I had been the picture-- the picture. Gisburn. I had been, and the of the of the of the the of the of the picture. I had the of the of the of the of the of the of\n",
      "Ep 5 (Step 000040): Train loss: 4.222, Val loss: 6.178\n",
      "Every effort moves you know the fact of the \"--I looked--and a little of the house-hum--and it's     \"I said--as Jack himself at the donkey.           \n",
      "Ep 6 (Step 000045): Train loss: 3.843, Val loss: 6.124\n",
      "Ep 6 (Step 000050): Train loss: 3.297, Val loss: 6.142\n",
      "Every effort moves you know the \"Oh, and in the \"I had the last word.           \"Oh, and I had a little the donkey. \"I, and down, and he was his\n",
      "Ep 7 (Step 000055): Train loss: 3.274, Val loss: 6.216\n",
      "Ep 7 (Step 000060): Train loss: 2.529, Val loss: 6.135\n",
      "Every effort moves you know the picture to have been too? I felt, and I felt him--so it was no I felt to me to have to see a smile behind his pictures that he had not till his painting, I had been--because he had the his\n",
      "Ep 8 (Step 000065): Train loss: 2.047, Val loss: 6.161\n",
      "Ep 8 (Step 000070): Train loss: 1.717, Val loss: 6.240\n",
      "Every effort moves you know,\" was one of the picture. Gisburn--as such--had not to my work, and!     \"Oh, and I had been the donkey--and I had the donkey. \"There were days when I\n",
      "Ep 9 (Step 000075): Train loss: 1.349, Val loss: 6.227\n",
      "Ep 9 (Step 000080): Train loss: 1.034, Val loss: 6.278\n",
      "Every effort moves you know,\" was not that my hostess was \"interesting\": on that I felt to have given Miss Croft the fact, and that, in the moment--as Jack himself, his pictures--the quality of Jack's \"strongest,\" she was\n",
      "Ep 10 (Step 000085): Train loss: 0.773, Val loss: 6.372\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=0.0004,\n",
    "    weight_decay=0.1\n",
    ")\n",
    "num_epochs = 10\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1e6971a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "    epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95123427",
   "metadata": {},
   "source": [
    "**Decoding strategies to control randomness**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057c0f2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm-testbed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
