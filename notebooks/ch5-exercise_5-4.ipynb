{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d90b7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set project_root: /home/sromo/Repos/lm-testbed\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parents[0]\n",
    "os.chdir(project_root)\n",
    "print(\"Set project_root:\", project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38531699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6353f091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "# Load the data\n",
    "file_path = project_root / \"data\" / \"raw\" / \"the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    text_data = f.read()\n",
    "\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8a8f943",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.9\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bb3d10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.configs.GPT2 import GPT_CONFIG_124M\n",
    "\n",
    "GPT_CONFIG_124M = GPT_CONFIG_124M.copy()\n",
    "GPT_CONFIG_124M[\"context_length\"] = 256 # Reduce context length to reduce computational demands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2b41020",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from src.dataloaders.GPT import create_dataloader_v1\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size = 2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size = 2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d3da860",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cff54b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.GPT2 import GPTModel\n",
    "\n",
    "# Loading Parameters AND optimizer state\n",
    "out_path = project_root / \"data\" / \"model_parameters\" / \"GPT2_124M\" / \"model_and_optimizer.pth\"\n",
    "\n",
    "checkpoint = torch.load(out_path, map_location=device)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device=device)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d477e428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss: 0.629, Val loss: 6.449\n",
      "Ep 1 (Step 000005): Train loss: 0.470, Val loss: 6.519\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back the window-curtains, as I turned, and down the room, when I\n"
     ]
    }
   ],
   "source": [
    "from src.training.trainer import train_model_simple\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm-testbed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
